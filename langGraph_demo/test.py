
import time
from openai import OpenAI

# æµ‹è¯• prompt å†…å®¹
prompt = "ç”Ÿæˆä¸€å¼ æ³¢æ–¯çŒ«çš„å›¾ç‰‡"

from config import model_configs

# ç»Ÿä¸€è¾“å‡ºæ ¼å¼
def print_result(name, token_count, start_time, first_token_time, end_time):
    print(f"\nğŸ§ª æ¨¡å‹åç§°ï¼š{name}")
    if first_token_time:
        print(f"â± é¦– token å“åº”æ—¶é—´ï¼š{first_token_time - start_time:.2f} ç§’")
    print(f"â± æ€»è€—æ—¶ï¼š{end_time - start_time:.2f} ç§’")
    if first_token_time:
        duration = end_time - first_token_time
        print(f"ğŸ“ˆ å¹³å‡ååç‡ï¼š{token_count / duration:.2f} tokens/sec")
    print("-" * 40)

# éå†æ¯ä¸ªæ¨¡å‹è¿›è¡Œæµ‹è¯•
for config in model_configs:
    print(f"\n========== æ­£åœ¨æµ‹è¯•æ¨¡å‹ï¼š{config['name']} ==========")
    client = OpenAI(
        base_url=config["base_url"],
        api_key=config["api_key"],
    )

    start_time = time.time()
    first_token_time = None
    token_count = 0

    response = client.chat.completions.create(
        messages=[{"role": "user", "content": prompt}],
        model=config["model"],
        temperature=1.0,
        stream=True,
        timeout=60
    )

    for chunk in response:
        delta = chunk.choices[0].delta
        if delta.content:
            print(delta.content, end="", flush=True)
            token_count += 1
            if first_token_time is None:
                first_token_time = time.time()

    end_time = time.time()
    print_result(config["name"], token_count, start_time, first_token_time, end_time)