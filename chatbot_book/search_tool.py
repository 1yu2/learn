import os
import sys
import json
from langchain.chat_models import init_chat_model
from langfuse import Langfuse
from langfuse.langchain import CallbackHandler
from typing import Annotated, Literal
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_core.tools import tool
from langchain_tavily import TavilySearch
from langchain_core.messages import ToolMessage, BaseMessage

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from config import model_configs, langfuse_configs, TAVILY_API_KEY

# è®¾ç½® Tavily API Key
os.environ["TAVILY_API_KEY"] = TAVILY_API_KEY

# å®šä¹‰çŠ¶æ€ç±»å‹
class State(TypedDict):
    messages: Annotated[list, add_messages]

# åˆå§‹åŒ– Langfuse
langfuse = Langfuse(**langfuse_configs)
langfuse_handler = CallbackHandler()

# åˆå§‹åŒ– LLM
llm = init_chat_model(
    **model_configs,
    callbacks=[langfuse_handler]
)

tavily = TavilySearch(max_results=2)

@tool
def web_search(query: str) -> dict:
    """ä½¿ç”¨ Tavily æœç´¢ç½‘ç»œä»¥è·å–æœ€æ–°ä¿¡æ¯ã€‚è¿”å›åŸå§‹ç»“æœå­—å…¸ï¼Œä¾¿äºåç»­å¤„ç†ã€‚"""
    print(f"\nğŸ” æ­£åœ¨æ‰§è¡Œç½‘ç»œæœç´¢: {query}")
    result = tavily.invoke({"query": query})
    
    # æ‰“å°çœŸå®æœç´¢ç»“æœï¼ˆå¯è¯»æ ¼å¼ï¼‰
    print("\n" + "="*60)
    print("ğŸŒ æœç´¢ç»“æœè¯¦æƒ…:")
    for i, item in enumerate(result.get("results", []), 1):
        print(f" {i}. [{item.get('title')}]({item.get('url')})")
        print(f"    {item.get('content')[:200]}...")
    print("="*60 + "\n")
    
    # è¿”å›åŸå§‹ dictï¼Œä¸è¦ json.dumpsï¼LangChain ä¼šè‡ªåŠ¨åºåˆ—åŒ–
    return result  # ç›´æ¥è¿”å› dict

tools = [web_search]
llm_with_tools = llm.bind_tools(tools)

# åˆ›å»ºçŠ¶æ€å›¾
graph_builder = StateGraph(State)

# å®šä¹‰èŠå¤©æœºå™¨äººèŠ‚ç‚¹
def chatbot(state: State):
    messages = state["messages"]
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}

graph_builder.add_node("chatbot", chatbot)

# å·¥å…·èŠ‚ç‚¹ï¼ˆæ— éœ€ä¿®æ”¹ï¼Œä½†å¢å¼ºæ‰“å°ï¼‰
class BasicToolNode:
    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}

    def __call__(self, inputs: dict):
        if messages := inputs.get("messages", []):
            message = messages[-1]
        else:
            raise ValueError("è¾“å…¥ä¸­æœªæ‰¾åˆ°æ¶ˆæ¯")

        outputs = []
        for tool_call in message.tool_calls:
            try:
                print(f"ğŸ› ï¸ æ‰§è¡Œå·¥å…·è°ƒç”¨: {tool_call['name']} (å‚æ•°: {tool_call['args']})")
                tool_result = self.tools_by_name[tool_call["name"]].invoke(tool_call["args"])
                outputs.append(
                    ToolMessage(
                        content=json.dumps(tool_result, ensure_ascii=False, indent=2),  # æ ¼å¼åŒ–å­—ç¬¦ä¸²ç”¨äºè°ƒè¯•
                        name=tool_call["name"],
                        tool_call_id=tool_call["id"],
                    )
                )
            except Exception as e:
                print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
                outputs.append(
                    ToolMessage(
                        content=f"å·¥å…·æ‰§è¡Œå‡ºé”™: {str(e)}",
                        name=tool_call["name"],
                        tool_call_id=tool_call["id"],
                    )
                )
        return {"messages": outputs}

tool_node = BasicToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

# è·¯ç”±å‡½æ•°
def route_tools(state: State) -> Literal["tools", "__end__"]:
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"è¾“å…¥çŠ¶æ€ä¸­æœªæ‰¾åˆ°æ¶ˆæ¯: {state}")

    tool_calls = getattr(ai_message, "tool_calls", [])
    print(f"ğŸš¦ è·¯ç”±åˆ¤æ–­: {'éœ€è¦è°ƒç”¨å·¥å…·' if tool_calls else 'æ— éœ€å·¥å…·'}")
    return "tools" if tool_calls else "__end__"

# æ·»åŠ æ¡ä»¶è¾¹
graph_builder.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", "__end__": END},
)

# æ·»åŠ è¾¹
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
graph_builder.add_edge("chatbot", END)

# ç¼–è¯‘å›¾
graph = graph_builder.compile()

# ä¸»å¾ªç¯
while True:
    user_input = input("\nUser: ")
    if user_input.lower() in ["quit", "exit", "q"]:
        print("ğŸ‘‹ Goodbye!")
        break

    # æµå¼æ‰§è¡Œ ceshi
    events = graph.stream({"messages": [("user", user_input)]})
    final_assistant_message = None

    for event in events:
        for value in event.values():
            messages = value.get("messages", [])
            if not messages:
                continue
            last_message = messages[-1]

            if isinstance(last_message, ToolMessage):
                try:
                    result = json.loads(last_message.content)  # ä¸ºäº†æ‰“å°æ ¼å¼åŒ–
                    print(f"âœ… å·¥å…·è¿”å›ç»“æœ ({last_message.name}):")
                    print(json.dumps(result, ensure_ascii=False, indent=2))
                except:
                    print(f"âœ… å·¥å…·è¿”å›: {last_message.content}")

            elif isinstance(last_message, BaseMessage):
                if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                    print(f"ğŸ¤– Assistant: æ­£åœ¨è°ƒç”¨å·¥å…· {[(t['name'], t['args']) for t in last_message.tool_calls]}")
                else:
                    final_assistant_message = last_message.content

    if final_assistant_message:
        print(f"ğŸ¤– Assistant: {final_assistant_message}")